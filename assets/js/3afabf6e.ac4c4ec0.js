"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1863],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),u=c(n),d=r,m=u["".concat(s,".").concat(d)]||u[d]||h[d]||i;return n?a.createElement(m,l(l({ref:t},p),{},{components:n})):a.createElement(m,l({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,l=new Array(i);l[0]=u;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,l[1]=o;for(var c=2;c<i;c++)l[c]=n[c];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},8689:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return o},contentTitle:function(){return s},metadata:function(){return c},toc:function(){return p},default:function(){return u}});var a=n(7462),r=n(3366),i=(n(7294),n(3905)),l=["components"],o={id:"Cachebench_FB_HW_eval",title:"Evaluating SSD hardware for Facebook workloads"},s=void 0,c={unversionedId:"Cache_Library_User_Guides/Cachebench_FB_HW_eval",id:"Cache_Library_User_Guides/Cachebench_FB_HW_eval",isDocsHomePage:!1,title:"Evaluating SSD hardware for Facebook workloads",description:"CacheBench is a cache benchmark tool used to stress the storage and",source:"@site/docs/Cache_Library_User_Guides/Cachebench_FB_HW_eval.md",sourceDirName:"Cache_Library_User_Guides",slug:"/Cache_Library_User_Guides/Cachebench_FB_HW_eval",permalink:"/docs/Cache_Library_User_Guides/Cachebench_FB_HW_eval",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/docs/Cache_Library_User_Guides/Cachebench_FB_HW_eval.md",tags:[],version:"current",frontMatter:{id:"Cachebench_FB_HW_eval",title:"Evaluating SSD hardware for Facebook workloads"},sidebar:"cachebenchSideBar",previous:{title:"Contributing to Cachebench",permalink:"/docs/Cache_Library_User_Guides/Developing_for_Cachebench"}},p=[{value:"System requirements",id:"system-requirements",children:[]},{value:"Set up the SSD devices using mdraid",id:"set-up-the-ssd-devices-using-mdraid",children:[]},{value:"Installing cachebench",id:"installing-cachebench",children:[]},{value:"Running the benchmark for SSD perf testing",id:"running-the-benchmark-for-ssd-perf-testing",children:[]},{value:"Tuning the workload and cache parameters",id:"tuning-the-workload-and-cache-parameters",children:[]},{value:"Getting the Results",id:"getting-the-results",children:[]},{value:"Plotting latency stats",id:"plotting-latency-stats",children:[]}],h={toc:p};function u(e){var t=e.components,n=(0,r.Z)(e,l);return(0,i.kt)("wrapper",(0,a.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"CacheBench")," is a cache benchmark tool used to stress the storage and\nmemory subsystem in a comparable way that they are stressed\nin production workloads. This doc describes how Facebook leverages CacheBench\nto validate SSD performance."),(0,i.kt)("h2",{id:"system-requirements"},"System requirements"),(0,i.kt)("p",null,"To run CacheBench, first ensure that the machine has\nsufficient free memory (50+GB) and SSD capacity (1TB)."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Memory: 64GB or more"),(0,i.kt)("li",{parentName:"ul"},"SSD Capacity: 100GB or more available capacity"),(0,i.kt)("li",{parentName:"ul"},"Internet connection capable of accessing github.com and installing packages")),(0,i.kt)("h2",{id:"set-up-the-ssd-devices-using-mdraid"},"Set up the SSD devices using mdraid"),(0,i.kt)("p",null,"To gather SSD performance metrics, the SSD must be setup first. An example\nbelow sets up a raid device to handle two ssds being used by CacheBench."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"mdadm --create /dev/md0 --force --raid-devices=2 --level=0 --chunk=256 /dev/nvme1n1 /dev/nvme2n1\n")),(0,i.kt)("h2",{id:"installing-cachebench"},"Installing cachebench"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"If you have not already, clone the cachelib repository from github.com:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"git clone https://github.com/facebook/CacheLib.git\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Build cachelib and ",(0,i.kt)("inlineCode",{parentName:"p"},"cachebench"),":"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd CacheLib\n./contrib/build.sh -j\n")),(0,i.kt)("p",{parentName:"li"},"Notes:"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"It will take several minutes to build and install all dependencies."),(0,i.kt)("li",{parentName:"ul"},"Remove ",(0,i.kt)("inlineCode",{parentName:"li"},"-j")," flag to build using only a single CPU (build will take longer)"),(0,i.kt)("li",{parentName:"ul"},"The script will automatically use ",(0,i.kt)("inlineCode",{parentName:"li"},"sudo")," to install several OS packages (using ",(0,i.kt)("inlineCode",{parentName:"li"},"apt"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"dnf"),", etc.)"),(0,i.kt)("li",{parentName:"ul"},"The build script has been tested to work on stable Debian, Ubuntu, CentOS, RockyLinux.\nOther systems are possible but not officially supported."))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"The resulting binaries and libraries will be in ",(0,i.kt)("inlineCode",{parentName:"p"},"./opt/cachelib"),":"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./opt/cachelib/bin/cachebench --help\n")),(0,i.kt)("p",{parentName:"li"},"or"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd ./opt/cachelib/bin/\n./cachebench --help\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Sample test configurations are provided in ",(0,i.kt)("inlineCode",{parentName:"p"},"./opt/cachelib/test_configs/"),".\nExample:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd ./opt/cachelib\n./bin/cachebench --json_test_config ./test_configs/simple_test.json\n")))),(0,i.kt)("details",null,(0,i.kt)("summary",null,"Expected Output of test run"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'$ cd ./opt/cachelib\n$ ./bin/cachebench --json_test_config ./test_configs/simple_test.json\n===JSON Config===\n// @nolint instantiates a small cache and runs a quick run of basic operations.\n{\n  "cache_config" : {\n    "cacheSizeMB" : 512,\n    "poolRebalanceIntervalSec" : 1,\n    "moveOnSlabRelease" : false,\n\n    "numPools" : 2,\n    "poolSizes" : [0.3, 0.7]\n  },\n  "test_config" : {\n\n      "numOps" : 100000,\n      "numThreads" : 32,\n      "numKeys" : 1000000,\n\n      "keySizeRange" : [1, 8, 64],\n      "keySizeRangeProbability" : [0.3, 0.7],\n\n      "valSizeRange" : [1, 32, 10240, 409200],\n      "valSizeRangeProbability" : [0.1, 0.2, 0.7],\n\n      "getRatio" : 0.15,\n      "setRatio" : 0.8,\n      "delRatio" : 0.05,\n      "keyPoolDistribution": [0.4, 0.6],\n      "opPoolDistribution" : [0.5, 0.5]\n    }\n}\n\nWelcome to OSS version of cachebench\nCreated 897,355 keys in 0.00 mins\nGenerating 1.60M sampled accesses\nGenerating 1.60M sampled accesses\nGenerated access patterns in 0.00 mins\nTotal 3.20M ops to be run\n12:07:12       0.00M ops completed\n== Test Results ==\n== Allocator Stats ==\nItems in RAM  : 96,995\nItems in NVM  : 0\nAlloc Attempts: 2,559,176 Success: 100.00%\nRAM Evictions : 2,163,672\nCache Gets    : 480,592\nHit Ratio     :  10.97%\nNVM Gets      :               0, Coalesced : 100.00%\nNVM Puts      :               0, Success   :   0.00%, Clean   : 100.00%, AbortsFromDel   :        0, AbortsFromGet   :        0\nNVM Evicts    :               0, Clean     : 100.00%, Unclean :       0, Double          :        0\nNVM Deletes   :               0 Skipped Deletes: 100.00%\nReleased 21 slabs\n  Moves     : attempts:          0, success: 100.00%\n  Evictions : attempts:      3,040, success:  99.57%\n\n== Throughput for  ==\nTotal Ops : 3.20 million\nTotal sets: 2,559,176\nget       :    49,453/s, success   :  10.97%\nset       :   263,344/s, success   : 100.00%\ndel       :    16,488/s, found     :  10.83%\n'))),(0,i.kt)("ol",{start:5},(0,i.kt)("li",{parentName:"ol"},"If fio is not installed, build it with:",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"git clone https://github.com/axboe/fio.git\ncd fio\n./configure\nmake\nmake install\n")))),(0,i.kt)("p",null,"See ",(0,i.kt)("a",{parentName:"p",href:"../installation/installation"},"build and installation")," for further details."),(0,i.kt)("h2",{id:"running-the-benchmark-for-ssd-perf-testing"},"Running the benchmark for SSD perf testing"),(0,i.kt)("p",null,"Cachebench has three configs packaged for SSD validation. These are under ",(0,i.kt)("inlineCode",{parentName:"p"},"test_configs/ssd_perf/<service-domain>"),'. Currently, we have "graph_cache_leader", "kvcache_reg", and "kvcache_wc" which represent three distinct cache workloads from Facebook. Below, we show how the benchmarks can be run for two of these workloads. It is important to trim the ssds between the runs to ensure any interference is avoided.'),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Change to the path where you previously copied cachebench to.",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd <your path>\n"))),(0,i.kt)("li",{parentName:"ol"},"If ",(0,i.kt)("inlineCode",{parentName:"li"},"/dev/md0")," is not being used, edit workload files appropiately.\nChange all instances of ",(0,i.kt)("inlineCode",{parentName:"li"},"/dev/md0")," to raw path of data SSD(s):",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"vi ./test_configs/ssd_perf/graph_cache_leader/config.json\nvi ./test_configs/ssd_perf/kvcache_l2_wc/config.json\n"))," See ",(0,i.kt)("a",{parentName:"li",href:"Configuring_cachebench_parameters#storage-filedevicedirectory-path-info"},"configuring storage path"),"  for more details on how to configure the storage path."),(0,i.kt)("li",{parentName:"ol"},"Before each benchmark run, fully trim the drive with fio:",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"fio --name=trim --filename=/dev/md0 --rw=trim --bs=3G\n"))),(0,i.kt)("li",{parentName:"ol"},"Execute social graph leader cache workload:",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./cachebench -json_test_config test_configs/ssd_perf/graph_cache_leader/config.json --progress_stats_file=/tmp/graph_cache_leader.log\n"))),(0,i.kt)("li",{parentName:"ol"},"Fully trim the drive with fio again:",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"fio --name=trim --filename=/dev/md0 --rw=trim --bs=3G\n"))),(0,i.kt)("li",{parentName:"ol"},"Execute the ",(0,i.kt)("inlineCode",{parentName:"li"},"kvcache")," workload:",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./cachebench -json_test_config test_configs/ssd_perf/kvcache_l2_wc/config.json \u2014progress_stats_file=/tmp/mc-l2-wc.log\n")))),(0,i.kt)("h2",{id:"tuning-the-workload-and-cache-parameters"},"Tuning the workload and cache parameters"),(0,i.kt)("p",null,"For a full list of options that can be configured, see ",(0,i.kt)("a",{parentName:"p",href:"Configuring_cachebench_parameters"},"configuring cachebench")),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Duration of Replay")," - To run cachebench operation for longer,\nincrease the ",(0,i.kt)("inlineCode",{parentName:"li"},"numOps")," appropriately in the config file."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Device Info")," - Device info is configured in the config file\nusing the ",(0,i.kt)("inlineCode",{parentName:"li"},"nvmCachePaths")," option.  If you would rather use a\nfilesystem based cache, pass the appropriate path through\n",(0,i.kt)("inlineCode",{parentName:"li"},"nvmCachePaths"),".  The benchmark will create a single file\nunder that path corresponding to the configured ",(0,i.kt)("inlineCode",{parentName:"li"},"nvmCacheSizeMB")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Watching Progress")," -  While the benchmark runs, you can monitor the\nprogress so far. The interval for progress update can be configured\nusing the ",(0,i.kt)("inlineCode",{parentName:"li"},"--progress")," and specifying a duration in seconds.\nIf ",(0,i.kt)("inlineCode",{parentName:"li"},"--progress-stats-file")," is also specified, on every progress\ninterval, ",(0,i.kt)("inlineCode",{parentName:"li"},"cachebench")," would log the internal stats to the specified file.")),(0,i.kt)("h2",{id:"getting-the-results"},"Getting the Results"),(0,i.kt)("p",null," View results summary through the log file:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"```sh\ntail -n 50 /tmp/graph_cache_leader.log\ntail -n 50 /tmp/mc-l2-wc.log\n```\n")),(0,i.kt)("h2",{id:"plotting-latency-stats"},"Plotting latency stats"),(0,i.kt)("p",null,"The stats output can be parsed to plot SSD latency information over time. To\ndo this, first ensure ",(0,i.kt)("inlineCode",{parentName:"p"},"gnuplot")," is installed. For example, on CentOs:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"yum install gnuplot\n")),(0,i.kt)("p",null,"Then run this command to get the latency stats:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"./vizualize/extract_latency.sh /tmp/graph_cache_leader.log\n./vizualize/extract_latency.sh /tmp/mc-l2-wc.log\n")),(0,i.kt)("p",null,"This should produce a tsv file for read latency, a tsv file for write latency, and the corresponding ",(0,i.kt)("inlineCode",{parentName:"p"},"png")," files that have the graphs plotted."))}u.isMDXComponent=!0}}]);